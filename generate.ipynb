{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pretty_midi\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_drum_pitch = 35\n",
    "max_drum_pitch = 81\n",
    "n_drum_pitches = max_drum_pitch - min_drum_pitch + 1\n",
    "\n",
    "min_pitch = 0\n",
    "max_pitch = 127\n",
    "n_pitches = max_pitch - min_pitch + 1\n",
    "\n",
    "sequence_length = 128\n",
    "n_velocities = 128\n",
    "n_instruments = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MusicGen\n",
    "model = MusicGen()\n",
    "model.load_state_dict(torch.load('models/model3-e10.pth', weights_only=True))\n",
    "denorm = torch.load('data/lmd-100-denorm.pth', weights_only=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, seed_sequence, steps=512, device='cpu'):\n",
    "  model.eval()\n",
    "  # seed_sequence: (1, 128, 5)\n",
    "  seed_sequence = seed_sequence.to(device)\n",
    "  # generated_sequence: (steps, 5)\n",
    "  generated_sequence = []\n",
    "  hidden = None\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _ in tqdm(range(steps)):\n",
    "      out, hidden = model(seed_sequence, hidden)\n",
    "      instrument = torch.argmax(out['instrument'], dim=-1).item()\n",
    "      drum_pitch = torch.multinomial(F.softmax(out['drum_pitch'], dim=-1), 1).item() + min_drum_pitch\n",
    "      regular_pitch = torch.multinomial(F.softmax(out['regular_pitch'], dim=-1), 1).item()\n",
    "      velocity = torch.multinomial(F.softmax(out['velocity'], dim=-1), 1).item()\n",
    "      step = out['step'].item()\n",
    "      duration = out['duration'].item()\n",
    "      generated_note = torch.tensor([0, velocity, duration, step, instrument], device=device)\n",
    "      if (instrument == 0):\n",
    "        generated_note[0] = drum_pitch\n",
    "      else:\n",
    "        generated_note[0] = regular_pitch\n",
    "      generated_sequence.append(generated_note)\n",
    "      \n",
    "      # newnote: (1, 1, 5) float32\n",
    "      seed_sequence = torch.cat([seed_sequence[:, 1:, :], generated_note.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "\n",
    "    generated_sequence = torch.stack(generated_sequence, dim=0)\n",
    "    generated_sequence[:, 2] = generated_sequence[:, 2] * denorm['std_duration'] + denorm['mean_duration']\n",
    "    generated_sequence[:, 3] = generated_sequence[:, 3] * denorm['std_step'] + denorm['mean_step']\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = torch.load('data/lmd-100.pth', weights_only=True)\n",
    "print(loaded_data['sequences'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_sequence = torch.zeros((1, sequence_length, 5))\n",
    "generated_notes = generate(model, loaded_data['sequences'][0].unsqueeze(0), steps=1000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_midi(seqs):\n",
    "    # Define MIDI program mapping for each instrument category\n",
    "    CATEGORY_PROGRAMS = {\n",
    "        0: (0, True),   # Drums (is_drum=True)\n",
    "        1: (32, False), # Bass (Acoustic Bass, program 32)\n",
    "        2: (0, False),  # Chords (Acoustic Grand Piano, program 0)\n",
    "        3: (56, False)  # Lead (Trumpet, program 56)\n",
    "    }\n",
    "\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instruments = {\n",
    "        i: pretty_midi.Instrument(program=CATEGORY_PROGRAMS[i][0], is_drum=CATEGORY_PROGRAMS[i][1])\n",
    "        for i in range(4)  # 0: Drums, 1: Bass, 2: Chords, 3: Lead\n",
    "    }\n",
    "    \n",
    "    current_time = 0.0\n",
    "    for i in range(seqs.shape[0]):\n",
    "        pitch = int(seqs[i, 0].item())\n",
    "        velocity = int(seqs[i, 1].item())\n",
    "        duration = float(seqs[i, 2].item())\n",
    "        step = float(seqs[i, 3].item())\n",
    "        instrument = int(seqs[i, 4].item())\n",
    "        current_time += step\n",
    "        end_time = current_time + duration\n",
    "        midi_note = pretty_midi.Note(\n",
    "            velocity=int(velocity),\n",
    "            pitch=int(pitch),\n",
    "            start=current_time,\n",
    "            end=end_time\n",
    "        )\n",
    "        \n",
    "        instruments[instrument].notes.append(midi_note)\n",
    "\n",
    "    for instr in instruments.values():\n",
    "        midi.instruments.append(instr)\n",
    "\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_midi = tensor_to_midi(generated_notes)\n",
    "generated_midi.write(\"generated/multi_instrument_v1_sample4.midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_notes.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
