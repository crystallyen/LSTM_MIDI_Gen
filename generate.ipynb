{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pretty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pitch = 21\n",
    "max_pitch = 108\n",
    "n_pitches = max_pitch - min_pitch + 1\n",
    "sequence_length = 128\n",
    "n_velocities = 128\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicGen(\n",
       "  (lstm): LSTM(4, 128, batch_first=True)\n",
       "  (pitch_layer): Linear(in_features=128, out_features=88, bias=True)\n",
       "  (velocity_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (step_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (duration_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import MusicGen\n",
    "model = MusicGen()\n",
    "model.load_state_dict(torch.load('models/model2-e3.pth', weights_only=True))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, seed_sequence, steps=512, device='cpu'):\n",
    "  model.eval()\n",
    "  # seed_sequence: (1, 128, 4)\n",
    "  seed_sequence = seed_sequence.to(device)\n",
    "  # generated_sequence: (steps, 4)\n",
    "  generated_sequence = []\n",
    "  hidden = None\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for _ in tqdm(range(steps)):\n",
    "      out, hidden = model(seed_sequence, hidden)\n",
    "      pitch_pred, velocity_pred, duration_pred, step_pred = torch.split(\n",
    "          out, [n_pitches, n_velocities, 1, 1], dim=-1\n",
    "      )\n",
    "      \n",
    "      pitch_probs = torch.softmax(pitch_pred, dim=-1)\n",
    "      velocity_probs = torch.softmax(velocity_pred, dim=-1)\n",
    "      \n",
    "      pitch = torch.multinomial(pitch_probs, num_samples=1).item()\n",
    "      velocity = torch.multinomial(velocity_probs, num_samples=1).item()\n",
    "      step = step_pred.item()\n",
    "      duration = duration_pred.item()\n",
    "      \n",
    "      generated_note = [pitch, velocity, step, duration]\n",
    "      generated_sequence.append(generated_note)\n",
    "      \n",
    "      # newnote: (1, 1, 4) float32\n",
    "      new_note = torch.tensor(generated_note, device=device).unsqueeze(0).unsqueeze(0)\n",
    "      seed_sequence = torch.cat([seed_sequence[:, 1:, :], new_note], dim=1)\n",
    "\n",
    "    generated_sequence = np.array(generated_sequence)\n",
    "    generated_sequence[:, 0] = generated_sequence[:, 0] + min_pitch\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030fd716243744dbad6d2331945c10a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_sequence = torch.zeros((1, sequence_length, 4))\n",
    "generated_notes = generate(model, seed_sequence, steps=480, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_midi = pretty_midi.PrettyMIDI()\n",
    "instrument = pretty_midi.Instrument(program=0)\n",
    "current_time = 0.0\n",
    "\n",
    "for pitch, velocity, duration, step in generated_notes:\n",
    "  current_time += step\n",
    "  note = pretty_midi.Note(\n",
    "    velocity=int(velocity),\n",
    "    pitch=int(pitch),\n",
    "    start=(current_time),\n",
    "    end=(current_time + duration)\n",
    "  )\n",
    "  instrument.notes.append(note)\n",
    "\n",
    "generated_midi.instruments.append(instrument)\n",
    "generated_midi.write(\"generated/2.midi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
