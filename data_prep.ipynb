{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_drum_pitch = 35\n",
    "max_drum_pitch = 81\n",
    "n_drum_pitches = max_drum_pitch - min_drum_pitch + 1\n",
    "\n",
    "min_pitch = 0\n",
    "max_pitch = 127\n",
    "n_pitches = max_pitch - min_pitch + 1\n",
    "\n",
    "sequence_length = 128\n",
    "n_velocities = 128\n",
    "n_instruments = 4\n",
    "\n",
    "max_files = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = list(Path(r\"../Lakh_MIDI_Dataset\").rglob(\"*.mid\"))\n",
    "print(len(midi_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return what an instrument be simplified to\n",
    "def categorize_instrument(instrument):\n",
    "  if instrument.is_drum:\n",
    "    return \"Drums\"\n",
    "  prog = instrument.program\n",
    "  if 32 <= prog < 40:\n",
    "    return \"Bass\"\n",
    "  if 80 <= prog < 88:\n",
    "    return \"Lead\"\n",
    "  if 40 <= prog < 48:\n",
    "    if \"violin\" in instrument.name.lower():\n",
    "      return \"Lead\"\n",
    "    else:\n",
    "      return \"Chords\"\n",
    "  #  pianos, organs, guitars, and synth pads\n",
    "  if (0 <= prog < 8) or (16 <= prog < 24) or (24 <= prog < 32) or (88 <= prog < 96):\n",
    "    return \"Chords\"\n",
    "  # default\n",
    "  return \"Chords\"\n",
    "\n",
    "CATEGORY_PROGRAMS = {\n",
    "  \"Drums\": (0, True),      # No Program\n",
    "  \"Bass\": (33, False),     # Acoustic Bass\n",
    "  \"Chords\": (0, False),    # Acoustic Grand Piano\n",
    "  \"Lead\": (56, False)      # Trumpet\n",
    "}\n",
    "\n",
    "# return a new midi object after merging similar instruments\n",
    "def merge_instruments(midi_obj):\n",
    "  merged_tracks = defaultdict(lambda: None)\n",
    "\n",
    "  for instrument in midi_obj.instruments:\n",
    "    category = categorize_instrument(instrument)\n",
    "    if category:\n",
    "      if merged_tracks[category] is None:\n",
    "        program, is_drum = CATEGORY_PROGRAMS[category]\n",
    "        merged_tracks[category] = pretty_midi.Instrument(\n",
    "            program=program, \n",
    "            is_drum=is_drum, \n",
    "            name=category\n",
    "        )\n",
    "      merged_tracks[category].notes.extend(instrument.notes)\n",
    "\n",
    "  CATEGORY_ORDER = [\"Drums\", \"Bass\", \"Chords\", \"Lead\"]\n",
    "  new_midi = pretty_midi.PrettyMIDI()\n",
    "  for cat in CATEGORY_ORDER:\n",
    "    if cat in merged_tracks and merged_tracks[cat] is not None:\n",
    "      new_midi.instruments.append(merged_tracks[cat])\n",
    "\n",
    "  return new_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch Range of Drum: 35-81\n",
    "# note_seq consists of notes which consists of pitch, velocity, duration, step, instrument(0:drum, 1:bass, 2:chords, 3:lead)\n",
    "def create_roll(midi_file):\n",
    "  # preprocessing and saving it into a single list containing all attributes\n",
    "  try:\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "      ex = pretty_midi.PrettyMIDI(str(midi_file))\n",
    "  except Exception as e:\n",
    "    return None\n",
    "  \n",
    "  ex = merge_instruments(ex)\n",
    "  \"\"\"\n",
    "  note_seq_list = [\n",
    "        (note.pitch, note.velocity, note.end - note.start, note.start, ins_idx)\n",
    "        for ins_idx, instrument in enumerate(ex.instruments[:4])\n",
    "        for note in instrument.notes\n",
    "    ]\n",
    "  \"\"\"\n",
    "  note_seq_list = [\n",
    "    (max(35, min(note.pitch, 81)) if ins_idx == 0 else note.pitch,\n",
    "     note.velocity, \n",
    "     note.end - note.start, \n",
    "     note.start, \n",
    "     ins_idx)\n",
    "    for ins_idx, instrument in enumerate(ex.instruments[:4])\n",
    "    for note in instrument.notes\n",
    "]\n",
    "\n",
    "\n",
    "  # sorting based on note start time\n",
    "  note_seq_arr = np.array(note_seq_list, dtype=np.float32)\n",
    "  del note_seq_list\n",
    "  note_seq_arr = note_seq_arr[np.argsort(note_seq_arr[:, 3])]\n",
    "\n",
    "  # converting start time to step\n",
    "  note_seq_arr[1:, 3] -= note_seq_arr[:-1, 3].copy()\n",
    "  note_seq_arr[0, 3] = 0\n",
    "\n",
    "  # convert to tensor\n",
    "  note_seq = torch.from_numpy(note_seq_arr)\n",
    "  return note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(roll, sequence_length):\n",
    "  sequences = torch.zeros((len(roll) - sequence_length - 1, sequence_length, 5), dtype=torch.float32)\n",
    "  targets = torch.zeros((len(roll) - sequence_length - 1, 5), dtype=torch.float32)\n",
    "  \n",
    "  for i in range(0, len(roll) - sequence_length - 1):\n",
    "    sequences[i] = roll[i:i + sequence_length]\n",
    "    targets[i] = roll[i + sequence_length]\n",
    "\n",
    "  return sequences, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "targets = []\n",
    "files_done = 0\n",
    "bar = tqdm(total=max_files)\n",
    "for idx, midi_file in enumerate(midi_files):\n",
    "  if (files_done == max_files):\n",
    "    print(f\"{max_files} valid files out of {idx + 1}\")\n",
    "    break\n",
    "  roll = create_roll(midi_file)\n",
    "  if roll is None:\n",
    "    continue\n",
    "  file_sequences, file_targets = create_sequence(roll, sequence_length)\n",
    "  sequences.append(file_sequences)\n",
    "  targets.append(file_targets)\n",
    "  files_done += 1\n",
    "  bar.update(1)\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_tensor = torch.cat(sequences, dim=0)\n",
    "targets_tensor = torch.cat(targets, dim=0)\n",
    "\n",
    "std_duration = sequences_tensor[:, :, 2].std()\n",
    "mean_duration = sequences_tensor[:, :, 2].mean()\n",
    "std_step = sequences_tensor[:, :, 3].std()\n",
    "mean_step = sequences_tensor[:, :, 3].mean()\n",
    "\n",
    "sequences_tensor[:, :, 2] = (sequences_tensor[:, :, 2] - mean_duration) / std_duration\n",
    "sequences_tensor[:, :, 3] = (sequences_tensor[:, :, 3] - mean_step) / std_step\n",
    "targets_tensor[:, 2] = (targets_tensor[:, 2] - mean_duration) / std_duration\n",
    "targets_tensor[:, 3] = (targets_tensor[:, 3] - mean_step) / std_step\n",
    "\n",
    "dataset_name = \"lmd\"\n",
    "torch.save({\"sequences\": sequences_tensor, \"targets\": targets_tensor}, f\"data/{dataset_name}-{max_files}.pth\")\n",
    "torch.save({\"std_duration\": std_duration, \"mean_duration\": mean_duration, \"std_step\": std_step, \"mean_step\": mean_step}, f\"data/{dataset_name}-{max_files}-denorm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequences_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_midi(seqs, output_file=\"output.mid\"):\n",
    "    # Define MIDI program mapping for each instrument category\n",
    "    CATEGORY_PROGRAMS = {\n",
    "        0: (0, True),   # Drums (is_drum=True)\n",
    "        1: (32, False), # Bass (Acoustic Bass, program 32)\n",
    "        2: (0, False),  # Chords (Acoustic Grand Piano, program 0)\n",
    "        3: (56, False)  # Lead (Trumpet, program 56)\n",
    "    }\n",
    "\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "    instruments = {\n",
    "        i: pretty_midi.Instrument(program=CATEGORY_PROGRAMS[i][0], is_drum=CATEGORY_PROGRAMS[i][1])\n",
    "        for i in range(4)  # 0: Drums, 1: Bass, 2: Chords, 3: Lead\n",
    "    }\n",
    "    \n",
    "    current_time = 0.0\n",
    "    for i in range(seqs.shape[0]):\n",
    "        pitch = int(seqs[i, 0].item())\n",
    "        velocity = int(seqs[i, 1].item())\n",
    "        duration = float(seqs[i, 2].item())\n",
    "        step = float(seqs[i, 3].item())\n",
    "        instrument = int(seqs[i, 4].item())\n",
    "        current_time += step\n",
    "        end_time = current_time + duration\n",
    "        midi_note = pretty_midi.Note(\n",
    "            velocity=int(velocity),\n",
    "            pitch=int(pitch),\n",
    "            start=current_time,\n",
    "            end=end_time\n",
    "        )\n",
    "        \n",
    "        instruments[instrument].notes.append(midi_note)\n",
    "\n",
    "    for instr in instruments.values():\n",
    "        midi.instruments.append(instr)\n",
    "\n",
    "    midi.write(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_to_midi(sequences[0][0], 'test9090.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(sequences_tensor.shape[0])):\n",
    "  for j in range(sequences_tensor.shape[1]):\n",
    "    if (sequences_tensor[i, j, 4] < 0 or sequences_tensor[i, j, 4] > 3):\n",
    "      print(\"impossible\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
